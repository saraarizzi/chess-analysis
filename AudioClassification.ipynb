{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNqblH5BpBGRNqcMF62m2z0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saraarizzi/chess-analysis/blob/main/AudioClassification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Iffjlz1mvmKz"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "import os\n",
        "from google.colab import drive\n",
        "from shutil import copyfile\n",
        "import shutil\n",
        "from time import time\n",
        "import tarfile\n",
        "import IPython.display as ipd\n",
        "from matplotlib import pyplot as plt\n",
        "from scipy.io import wavfile as wav\n",
        "from scipy.fft import rfft, fft, irfft, ifft, fftfreq\n",
        "from scipy.signal import fftconvolve\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "import librosa\n",
        "import librosa.display\n",
        "from sklearn.preprocessing import scale"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')\n",
        "tar_path = '/content/drive/MyDrive/recordings.tar'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v342MoMvvsvW",
        "outputId": "15410d3b-098c-4223-96de-a0c06182f120"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with tarfile.open(tar_path, 'r') as tar_ref:\n",
        "    tar_ref.extractall('/content/drive/MyDrive/audio_unzipped')"
      ],
      "metadata": {
        "id": "GQ_Tcrj7vvYT"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# shutil.rmtree('/content/drive/MyDrive/audio_unzipped')"
      ],
      "metadata": {
        "id": "2KhYe4RbyxKn"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ci occupiamo ora di fare **classfiicazione**, ovvero a partire dal dataset di soggetti diversi che pronunciano le cifre, cercare di classificare la voce associandola alla persona corretta.\n",
        "Oppure, possiamo fare in modo di classificare per la corretta cifra pronunciata.\n",
        "\n",
        "Per i task di classificazione, dunque di ML, a differenza degli approcci di deep learnin come le reti neurali, non possiamo passare in input il dato grezzo, ma bisogna processarne ed estrarne le **features**, da usare per il modello di classificazione.\n",
        "\n",
        "Andremo pertanto a calcolare una serie di indicatori (media della frequenza, min max etc.).\n",
        "\n",
        "Come sappiamo, avremo bisogno di una fase di addestramento, e le corrispondenti classi (es. possiamo usare come classe la cifra associata alla pronuncia)."
      ],
      "metadata": {
        "id": "trB18jxjv0bM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataloader"
      ],
      "metadata": {
        "id": "7p3mEo0kz5gA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Per prima cosa inizializziamo il **dataloader**, ossia una classe python, o una funzione, il cui scopo è caricare e fornire al sistema i dati necessari all'addestramento, preparati secondo quanto indicheremo noi."
      ],
      "metadata": {
        "id": "R9zQFYW3z-RR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Placecholder for feature extractor\n",
        "# Tuttavia, se usassimo il segnale grezzo per le funzioni successive,\n",
        "# il codice non funzionerà, poichè i segnali hanno tutti len() diverse,\n",
        "# pertanto dobbiamo rincodurli tutti alla stessa len()\n",
        "def identity(input):\n",
        "    return input\n",
        "\n",
        "# Estraiamo i primi 100 elementi delle tracce audio. Se len()<100, allora\n",
        "# appplichiamo un padding di zeri alla fine dell'array, per renderlo len()==100\n",
        "def crop(input):\n",
        "    if len(input) < 100:\n",
        "        output = np.pad(input, (0, 100 - len(input)))\n",
        "    else:\n",
        "      output = input[:100]\n",
        "    return output\n",
        "\n",
        "# funzione del Data loader vera e propria\n",
        "# come parametri è passato l'input grezzo (funzione identità),\n",
        "def load_data(feature_extractor=identity, normalize=False):\n",
        "\n",
        "    labels = [] # inizializza la lista delle etichette\n",
        "    features = [] # inizializza le features\n",
        "\n",
        "    directory = '/content/drive/MyDrive/audio_unzipped/recordings/'\n",
        "    for f in sorted(os.listdir(directory)): # ciclo che legge i file .wav...\n",
        "        if f.endswith('.wav'):\n",
        "            # Load file and compute the requested features\n",
        "            _, signal = wav.read(directory + f)   # ... li importa, senza salvare il sample_rate poichè è sempre uguale\n",
        "            cur_features = feature_extractor(signal) # il segnale letto alla riga precedente è passato come parametro per\n",
        "            features.append(cur_features) # la funzione di feature_extraction, ed esse saranno aggiunte alla lista associata\n",
        "\n",
        "            # Classes\n",
        "            label = f.split('_')[0]  # isoliamo le classi\n",
        "            labels.append(label) # e le appendiamo alla lista corrispondente\n",
        "\n",
        "    # X: features, y: labels\n",
        "    # Prepariamo il train e test set, con prop 90-10\n",
        "    X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.1, random_state=1)\n",
        "  # random_state è un seed per la selezione casuale dei dati, che quindi diventa riproducibile\n",
        "    if normalize:\n",
        "        eps = 0.001\n",
        "        X_train = np.array(X_train)\n",
        "        X_train_mean = X_train.mean(axis=0)\n",
        "        X_train_std = X_train.std(axis=0)\n",
        "        X_train = (X_train - X_train_mean + eps)/(X_train_std + eps)\n",
        "        X_train = [row for row in X_train]\n",
        "\n",
        "        X_test = [row for row in (np.array(X_test) - X_train_mean + eps)/(X_train_std + eps)]\n",
        "\n",
        "    return X_train, X_test, y_train, y_test"
      ],
      "metadata": {
        "id": "d-sv63H3wP4m"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Usiamo adesso il **data_loader**.\n",
        "Passeremo come parametro la funzione 'crop' al feature_extractor"
      ],
      "metadata": {
        "id": "3KORJt_Z9KyH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = load_data(feature_extractor=crop, normalize=True)"
      ],
      "metadata": {
        "id": "O1m6jHnl9KRn"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Verifichiamo la grandezza di X_train ossia quante tracce audio\n",
        "# sono entrate nel training\n",
        "len(X_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9o1l6cuyBVtT",
        "outputId": "3d7a3b38-200c-4a4b-a6c0-5baee57c0f61"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1350"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Verifichiamo che al funzione 'crop' abbia funzionato.\n",
        "Mi aspetto che tutti gli elementi di X_train abbiano stessa shape, ovvero [100,]"
      ],
      "metadata": {
        "id": "IcdjRxCgA3N6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ne prendiamo alcuni a caso\n",
        "print(X_train[0].shape)\n",
        "print(X_train[120].shape)\n",
        "print(X_train[490].shape)\n",
        "print(X_train[760].shape)\n",
        "print(X_train[1200].shape)\n",
        "\n",
        "# Abbiamo verificato che tutte le tracce hanno stessa shape di campioni"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YIO1fX2JAtR9",
        "outputId": "9609d2a9-3ad9-44d6-dd37-9726f890daaf"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(100,)\n",
            "(100,)\n",
            "(100,)\n",
            "(100,)\n",
            "(100,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SVM application"
      ],
      "metadata": {
        "id": "XtMxaBVvBsJr"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "P5T2OoF5Bt2_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}